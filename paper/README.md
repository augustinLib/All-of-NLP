# paper
각종 논문들을 읽고 리뷰한 내용들을 모아놓은 곳입니다.


깃허브 마크다운 LaTex 렌더링 이슈로 인헤, 각 설명 문서 당 .pdf와 .md 두 개의 버전으로 올렸습니다.  
또한, 아래의 링크에서도 확인해보실 수 있습니다.

  
    
<br>

### 🚀TISTORY LINK🚀
[Attention is all you need](https://gbdai.tistory.com/46)  

[BERT: Pre training of Deep Bidirectional Transformers for Language Understanding](https://gbdai.tistory.com/50)  

[Effective Approaches to Attention based Neural Machine Translation](https://gbdai.tistory.com/45)  

[GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding](https://gbdai.tistory.com/51)  

[Improving Language Understanding by Generative Pre Training](https://gbdai.tistory.com/49)  

[Mixed Precision Training](https://gbdai.tistory.com/40)  

[Neural Machine Translation by Jointly Learning to Align and Translate](https://gbdai.tistory.com/44)  

[Using the Output Embedding to Improve Language Models](https://gbdai.tistory.com/48)  


