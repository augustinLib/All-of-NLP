# Benchmark

## Benchmark Dataset
SQuAD, WNLIdataset과 같이 Benchmark dataset에 대해 다루는 곳입니다.  

<br>


### List
- **Dataset Name** : Dataset의 이름(관련 페이지 링크)
- **각 Benchmark 이름 혹은 FLAN, T0** : 해당 벤치마크 혹은 FLAN, T0에서 어떠한 task로 사용되었는지 표시합니다. (사용되지 않았다면 공란)


| Dataset Name | GLUE | SuperGLUE | KILT | BEIR | T0 | FLAN | 
|:---------:|:----------:|:----------:|:-------------:|:----------:|:---------:|:------------:|
| [Adversarial QA](https://paperswithcode.com/dataset/adversarialqa) | - | - | - | - | Extractive QA | - |
| [AG News](https://paperswithcode.com/dataset/ag-news) | - | - | - | - | Topic Classification | Summarization |
| [AIDA CoNLL-YAGO](https://paperswithcode.com/dataset/aida-conll-yago) | - | - | Entity Linking | - | - | - |
| [ANLI](https://paperswithcode.com/dataset/anli) | - | - | - | - | NLI | NLI |
| [ARC](https://paperswithcode.com/dataset/arc) | - | - | - | - | - | Closed-Book QA |
| [BoolQ](https://paperswithcode.com/dataset/boolq) | - | QA | - | - | - | Reading Comprehension |
| [CB](https://super.gluebenchmark.com/tasks) | - | NLI | - | - | NLI | NLI |
| [CNN-DM](https://paperswithcode.com/dataset/cnn-daily-mail-1) | - | - | - | - | Summarization | Summarization |
| [CoLA](https://gluebenchmark.com/tasks) | Sentence Acceptability | - | - | - | - | Misc. |
| [Common Gen](https://paperswithcode.com/dataset/commongen) | - | - | - |  | Structure-To-Te-t | Structure-To-Te-t |
| [CommonsenseQA](https://paperswithcode.com/dataset/commonsenseqa) | - | - | - | - | Multiple-Choice QA | - |
| [COPA](https://paperswithcode.com/dataset/copa) | - | - | - | - | Sentence Completion | Commonsense |
| [CoQA](https://paperswithcode.com/dataset/coqa) | - | QA | - | - | - | Misc. |
| [Cosmos QA](https://paperswithcode.com/dataset/cosmosqa) | - | - | - | - | Multiple-Choice QA | Reading Comprehension/Commonsense |
| [DREAM](https://paperswithcode.com/dataset/dream) | - | - | - | - | Multiple-Choice QA | - |
| [DROP](https://paperswithcode.com/dataset/drop) | - | - | - | - | - | Reading Comprehension |
| [DuoRC](https://paperswithcode.com/dataset/duorc) | - | - | - | - | Extractive QA | - |
| [E2ENLG](https://paperswithcode.com/dataset/e2e) | - | - | - | - | - | Structure-To-Text |
| [ELI5](https://paperswithcode.com/dataset/eli5) | - | - | Open-domain QA | - | - | - |
| [Fever](https://paperswithcode.com/dataset/fever) | - | - | Fact Checking | Fact Checking | - | - |
| [Gigaword](https://metate-t.io/datasets/gigaword) | - | - | - | - | Summarization | Summarization |
| [HellaSwag](https://paperswithcode.com/dataset/hellaswag) | - | - | - | - | Sentence Completion | Commonsense |
| [Hotpot QA](https://paperswithcode.com/dataset/hotpotqa) | - | - | Open-domain QA | Open-domain QA | Closed-Book QA | - |
| [IMDB](https://paperswithcode.com/dataset/imdb-movie-reviews) | - | - | - | - | Sentiment | Sentiment |
| [Math](https://paperswithcode.com/dataset/math) | - | - | - | - | - | Misc. |
| [MNLI](https://paperswithcode.com/dataset/multinli) | NLI | - | - | - | - | NLI |
| [MRPC](https://paperswithcode.com/dataset/mrpc) | Paraphrase Identification | - | - | - | Paraphrase Identification | Paraphrase Identification |
| [MS-MARCO](https://paperswithcode.com/dataset/ms-marco) | - | - | - | Passage Retrieval | - | - |
| [MultiNews](https://paperswithcode.com/dataset/multi-news) | - | - | - | - | Summarization | Summarization |
| [MultiRC](https://paperswithcode.com/dataset/multirc) | - | QA | - | - | - | Reading Comprehension |
| [Newsroom](https://paperswithcode.com/dataset/newsroom) | - | - | - | - | - | Summarization |
| [NQ(Natural Question)](https://paperswithcode.com/dataset/natural-questions) | - | - | - | - | - | Closed-Book QA |
| [OBQA](https://paperswithcode.com/dataset/openbookqa) | - | - | - | - | - | Reading Comprehension |
| [PAWS](https://paperswithcode.com/dataset/paws) | - | - | - | - | Paraphrase Identification | Paraphrase Identification |
| [PiQA](https://paperswithcode.com/dataset/piqa) | - | - | - | - |  | Commonsense |
| [QASC](https://paperswithcode.com/dataset/qasc) | - | - | - | - | Multiple-Choice QA | - |
| [QNLI](https://paperswithcode.com/dataset/qnli) | QA/NLI | - | - | - | - | NLI |
| [QQP](https://gluebenchmark.com/tasks) | Paraphrase Identification | - | - | - | Paraphrase Identification | Paraphrase Identification |
| [QuAC](https://paperswithcode.com/dataset/quac) | - | - | - | - | - | Misc. |
| [QuAIL](https://paperswithcode.com/dataset/quail) | - |  |  | - | Multiple-Choice QA | - |
| [QuaRel](https://paperswithcode.com/dataset/quarel) | - | - | - | - | Multiple-Choice QA | - |
| [QuaRTz](https://paperswithcode.com/dataset/quartz) | - | - | - | - | Multiple-Choice QA | - |
| [Quoref](https://paperswithcode.com/dataset/quoref) | - | - | - | - | Extractive QA | - |
| [ReCoRD](https://paperswithcode.com/dataset/record) | - | QA | - | - |  | Reading Comprehension/Commonsense |
| [ROPES](https://paperswithcode.com/dataset/ropes) | - | - | - | - | Extractive QA | - |
| [Rotten Tomatoes](https://huggingface.co/datasets/rotten_tomatoes) | - | - | - | - | Sentiment | - |
| [RTE](https://paperswithcode.com/dataset/rte) | NLI | NLI | - | - | NLI | NLI |
| [SamSum](https://paperswithcode.com/dataset/samsum-corpus) | - | - | - | - | Summarization | Summarization |
| [SciQ](https://paperswithcode.com/dataset/sciq) | - | - | - | - | Multiple-Choice QA | - |
| [Sent140](https://paperswithcode.com/dataset/sentiment140) | - | - | - | - | - | Sentiment |
| [Social IQA](https://paperswithcode.com/dataset/social-iqa) | - | - | - | - | - | NLI |
| [SNLI](https://paperswithcode.com/dataset/snli) | - | - | - | - | Multiple-Choice QA | - |
| [SQuAD](https://paperswithcode.com/dataset/squad) | - | - | - | - | - | Reading Comprehension |
| [SST-2](https://paperswithcode.com/dataset/sst-2) | Sentiment | - | - | - | - | - |
| [Story Cloze](https://paperswithcode.com/dataset/storycloze) | - | - | - | - | Sentence Completion | Commonsense |
| [STS-B](https://paperswithcode.com/dataset/sts-benchmark) | Sentence Similarity | - | - | - | - | Paraphrase Identification |
| [T-REx](https://paperswithcode.com/dataset/t-rex) | - | - | Slot Filling | - | - | - |
| [TQA](https://paperswithcode.com/dataset/tqa) | - | - | Open-domain QA | - | - | Closed-Book QA |
| [TREC](https://paperswithcode.com/dataset/trec-10) | - | - | - | - | Topic Classification | Misc. |
| [WEBNLG](https://paperswithcode.com/dataset/webnlg) | - | - | - | - | - | Structure-To-Text |
| [WiC](https://paperswithcode.com/dataset/wic) | - | Word Sense Disambiguation | - | - | Word Sense Disambiguation | Misc. |
| [Wiki Hop](https://paperswithcode.com/dataset/wikihop) | - | - | - | - | Multiple-Choice QA | - |
| [Wiki QA](https://paperswithcode.com/dataset/wikiqa) | - | - | - | - | Closed-Book QA | - |
| [WikiBio](https://paperswithcode.com/dataset/wikibio) | - | - | - | - | Structure-To-Text | - |
| [Winogrande](https://paperswithcode.com/dataset/winogrande) | - | - | - | - | Coreference Resolution | - |
| [WiQA](https://paperswithcode.com/dataset/wiqa) | - | - | - | - | Multiple-Choice QA | - |
| [Wizard of Wikipedia](https://paperswithcode.com/dataset/wizard-of-wikipedia) | - | - | Dialogue | - | - | - |
| [WNLI](https://gluebenchmark.com/tasks) | NLI | - | - | - | - | NLI |
| [WSC](https://paperswithcode.com/dataset/wsc) | - | Conference Resolution | - | - | Conference Resolution | - |
| [Xsum](https://paperswithcode.com/dataset/xsum) | - | - | - | - | Summarization | Summarization |
| [Yelp](https://paperswithcode.com/dataset/yelp2018) | - | - | - | - | Sentiment | Sentiment |
